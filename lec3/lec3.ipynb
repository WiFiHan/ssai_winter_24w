{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7b712b-abe8-4677-b006-001e8b1e9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchtext\n",
    "\n",
    "def visualize_mnist(dataloader, model=None, title=\"\"):\n",
    "    x, y = next(iter(dataloader_test))\n",
    "    fig, axes = plt.subplots(2, 5, layout=\"constrained\")\n",
    "    for i in range(10):\n",
    "        ax = axes[i//5, i%5]\n",
    "        for j in range(BATCH_SIZE):\n",
    "            if y[j].item() == i:\n",
    "                break\n",
    "#         plt.subplot(2, 5, i+1)\n",
    "        ax.imshow(x[j, 0], cmap='gray')\n",
    "        if model is not None:\n",
    "            y_hat = model(x[j:j+1].cuda()).argmax()\n",
    "            ax.set_title(f\"Prediction: {y_hat.item()}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Answer: {y[j].item()}\")\n",
    "        ax.axis('off')\n",
    "    fig.tight_layout(pad=0.2, h_pad=-5)\n",
    "    fig.suptitle(title, y=0.93)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c3e65-8ba9-496b-99b7-157c9c253d61",
   "metadata": {},
   "source": [
    "# Lab3-1. Image Classification Using FC Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "LR = 0.001\n",
    "TOTAL_EPOCH = 10\n",
    "\n",
    "# Prepare MNIST datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                        # 입력을 PyTorch tensor로 바꾸겠다\n",
    "    transforms.Normalize((0.1307,), (0.3081,))    # mean=0.1307, std=0.3081 로 normalize 하겠다\n",
    "])\n",
    "dataset_train = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "dataset_test = datasets.MNIST('../data', train=False, transform=transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Visualize\n",
    "visualize_mnist(dataloader_test, title=\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1642df5-e04f-437a-ba91-de8bf07352b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch_size, Channels, Height, Width] = [500, 1, 28, 28]\n",
    "        x = x.reshape(-1, 28*28) # x.shape: [Batch_size, 768]\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net(1024).cuda()  # Create a network (parameters are randomly initialized)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)  # Create an optimizer\n",
    "\n",
    "\n",
    "# Visualize model predictions before training\n",
    "visualize_mnist(dataloader_test, model, \"Model prediction before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ce0ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    iteration = 0\n",
    "    for x, target in dataloader:\n",
    "        iteration = iteration + 1\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        if iteration % 10 == 0:\n",
    "            print(\n",
    "                f'\\r[Training...] Epoch: {epoch}, '\n",
    "                f'Iteration: {iteration}/{len(dataloader)}, '\n",
    "                f'train_loss: {train_loss / iteration:.4f}',\n",
    "                flush=True,\n",
    "                end=\"\"\n",
    "            )\n",
    "    return train_loss / iteration\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    iteration = 0\n",
    "    for x, target in dataloader:\n",
    "        iteration = iteration + 1\n",
    "        x, target = x.cuda(), target.cuda()\n",
    "        output = model(x)\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        pred = output.argmax(dim=1)  # get the index of the max log-probability\n",
    "        correct += (pred == target).sum().item()\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / len(dataloader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "# 학습 전의 loss 측정\n",
    "test_loss, test_accuracy = test(model, dataloader_test)\n",
    "print(f\"\\rBefore Training - \"\n",
    "      f\"test_loss: {test_loss:.4f}, test_accuracy: {test_accuracy:.1f}%\")\n",
    "\n",
    "\n",
    "# 학습 하면서 loss 측정\n",
    "for epoch in range(1, TOTAL_EPOCH+1):\n",
    "    train_loss = train(model, dataloader_train, optimizer, epoch)\n",
    "    test_loss, test_accuracy = test(model, dataloader_test)\n",
    "    print(f\"\\rEpoch {epoch} - train_loss: {train_loss:.4f}, \"\n",
    "          f\"test_loss: {test_loss:.4f}, test_accuracy: {test_accuracy:.1f}%\")\n",
    "\n",
    "\n",
    "# Visualize model predictions after training\n",
    "visualize_mnist(dataloader_test, model, \"Model prediction after training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10172fdf-506c-4ef7-a669-7679f6955e81",
   "metadata": {},
   "source": [
    "# Lab3-2. Image Classification Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f61a01-6a79-4986-b8a9-c2e9cab88ee3",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "LR = 0.001\n",
    "TOTAL_EPOCH = 10\n",
    "\n",
    "\n",
    "# Prepare MNIST datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "dataset_train = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "dataset_test = datasets.MNIST('../data', train=False, transform=transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Define a network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        self.fc = nn.Linear(128*3*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [Batch_size, 1, 28, 28]\n",
    "        x = self.conv1(x)       # x.shape = [BATCH_SIZE, 32, 28, 28]\n",
    "        x = F.relu(x)\n",
    "        x = self.avgpool(x)     # x.shape = [BATCH_SIZE, 32, 14, 14]\n",
    "        x = self.conv2(x)       # x.shape = [BATCH_SIZE, 64, 14, 14]\n",
    "        x = F.relu(x)\n",
    "        x = self.avgpool(x)     # x.shape = [BATCH_SIZE, 64, 7, 7]\n",
    "        x = self.conv3(x)       # x.shape = [BATCH_SIZE, 128, 7, 7]\n",
    "        x = F.relu(x)\n",
    "        x = self.avgpool(x)     # x.shape = [BATCH_SIZE, 128, 3, 3]\n",
    "        x = torch.flatten(x, 1) # x.shape = [BATCH_SIZE, 128*3*3]\n",
    "        x = self.fc(x)         # x.shape = [BATCH_SIZE, 10]\n",
    "        # output = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net().cuda()  # Create a network (parameters are randomly initialized)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)  # Create an optimizer\n",
    "\n",
    "\n",
    "# Visualize model predictions before training\n",
    "visualize_mnist(dataloader_test, model, \"Model prediction before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ae86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 하기 전의 loss 측정\n",
    "test_loss, test_accuracy = test(model, dataloader_test)\n",
    "print(f\"\\rBefore Training - \"\n",
    "      f\"test_loss: {test_loss:.4f}, test_accuracy: {test_accuracy:.1f}%\")\n",
    "\n",
    "\n",
    "# Train & validate 하면서 loss 측정\n",
    "for epoch in range(1, TOTAL_EPOCH+1):\n",
    "    train_loss = train(model, dataloader_train, optimizer, epoch)\n",
    "    test_loss, test_accuracy = test(model, dataloader_test)\n",
    "    print(f\"\\rEpoch {epoch} - train_loss: {train_loss:.4f}, \"\n",
    "          f\"test_loss: {test_loss:.4f}, test_accuracy: {test_accuracy:.1f}%\")\n",
    "\n",
    "\n",
    "# Visualize model predictions after training\n",
    "visualize_mnist(dataloader_test, model, \"Model prediction after training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afa228-5f0d-41b6-b941-261e6a3ab1db",
   "metadata": {},
   "source": [
    "# Lab3-3. Text Classification Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c05e6-e2b6-4440-9f37-6d058f8c66b8",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare IMDB datasets\n",
    "TEXT = torchtext.data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, batch_first=True)\n",
    "dataset_train, dataset_test = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "\n",
    "# Print datasets\n",
    "print(vars(dataset_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=5)\n",
    "LABEL.build_vocab(trainset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
