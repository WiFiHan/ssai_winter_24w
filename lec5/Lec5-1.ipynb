{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CiRb7M3naHyo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for MNIST data\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HrhXIwtAqM7H"
   },
   "outputs": [],
   "source": [
    "# download the MINST data\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(), # data를 pytorch의 tensor형식으로 바꿉니다\n",
    "    transforms.Normalize([0.5], [0.5]) # 픽셀값을 0 ~ 1에서 -1 ~ 1 로 바꿔줍니다.\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "\n",
    "# data를 batch size만큼만 가져오는 dataloader를 만듭니다.\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "hpPi14eUzLWI",
    "outputId": "e386ad8e-1014-4990-dc24-66717963e90c"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ONQYN5Neow0A"
   },
   "outputs": [],
   "source": [
    "# image\n",
    "\n",
    "channels = 1\n",
    "img_size = 28\n",
    "\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hj5al6cTZES1"
   },
   "outputs": [],
   "source": [
    "# dimensionality of the latent space\n",
    "# latent vector를 추출하기 위한 noise 분포의 dimension (정규분포를 따름)\n",
    "latent_dim = 100\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # generater의 model은 여러개의 block을 쌓아서 만들어짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z : input noise vector\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M_kvtvOhaLX6"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tBZf0BmBaN7l"
   },
   "outputs": [],
   "source": [
    "''' Hyper parameter '''\n",
    "# learning rate\n",
    "lr = 0.0002\n",
    "\n",
    "# decay of first order momentum of gradient\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Adam Optimizer\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KanyJ4VjrCUl"
   },
   "outputs": [],
   "source": [
    "# GPU\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "if cuda :\n",
    "  generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srQI5xI6ar-X",
    "outputId": "a00d9b45-4d71-4af2-ffb1-19f76ee2d419"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.42430.ECE-util1/ipykernel_3677703/3635232395.py:19: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.539800] [G loss: 0.759006] [Elapsed time: 2.27s]\n",
      "[Epoch 1/200] [D loss: 0.513687] [G loss: 1.833402] [Elapsed time: 4.55s]\n",
      "[Epoch 2/200] [D loss: 0.354392] [G loss: 1.340524] [Elapsed time: 6.75s]\n",
      "[Epoch 3/200] [D loss: 0.394829] [G loss: 1.536146] [Elapsed time: 9.09s]\n",
      "[Epoch 4/200] [D loss: 0.575400] [G loss: 0.505671] [Elapsed time: 11.29s]\n",
      "[Epoch 5/200] [D loss: 0.347583] [G loss: 1.070526] [Elapsed time: 13.52s]\n",
      "[Epoch 6/200] [D loss: 0.374206] [G loss: 1.409328] [Elapsed time: 15.80s]\n",
      "[Epoch 7/200] [D loss: 1.126805] [G loss: 5.243179] [Elapsed time: 18.03s]\n",
      "[Epoch 8/200] [D loss: 0.423612] [G loss: 2.843796] [Elapsed time: 20.19s]\n",
      "[Epoch 9/200] [D loss: 0.245025] [G loss: 1.700214] [Elapsed time: 22.36s]\n",
      "[Epoch 10/200] [D loss: 0.369606] [G loss: 0.930427] [Elapsed time: 24.53s]\n",
      "[Epoch 11/200] [D loss: 0.308333] [G loss: 3.549380] [Elapsed time: 26.68s]\n",
      "[Epoch 12/200] [D loss: 0.462115] [G loss: 1.109683] [Elapsed time: 28.80s]\n",
      "[Epoch 13/200] [D loss: 0.171870] [G loss: 1.736112] [Elapsed time: 30.96s]\n",
      "[Epoch 14/200] [D loss: 0.221248] [G loss: 2.575484] [Elapsed time: 33.22s]\n",
      "[Epoch 15/200] [D loss: 0.246287] [G loss: 1.517122] [Elapsed time: 35.31s]\n",
      "[Epoch 16/200] [D loss: 0.292174] [G loss: 4.486631] [Elapsed time: 37.56s]\n",
      "[Epoch 17/200] [D loss: 0.415523] [G loss: 0.942078] [Elapsed time: 39.81s]\n",
      "[Epoch 18/200] [D loss: 0.382092] [G loss: 3.139472] [Elapsed time: 41.99s]\n",
      "[Epoch 19/200] [D loss: 0.177139] [G loss: 1.859916] [Elapsed time: 44.28s]\n",
      "[Epoch 20/200] [D loss: 0.097485] [G loss: 2.839863] [Elapsed time: 46.32s]\n",
      "[Epoch 21/200] [D loss: 0.752143] [G loss: 0.476974] [Elapsed time: 48.57s]\n",
      "[Epoch 22/200] [D loss: 0.145694] [G loss: 2.320709] [Elapsed time: 50.70s]\n",
      "[Epoch 23/200] [D loss: 0.513531] [G loss: 5.617895] [Elapsed time: 52.82s]\n",
      "[Epoch 24/200] [D loss: 0.425717] [G loss: 0.945057] [Elapsed time: 55.10s]\n",
      "[Epoch 25/200] [D loss: 0.206450] [G loss: 2.106236] [Elapsed time: 57.25s]\n",
      "[Epoch 26/200] [D loss: 0.231126] [G loss: 1.637670] [Elapsed time: 59.39s]\n",
      "[Epoch 27/200] [D loss: 0.274694] [G loss: 1.837254] [Elapsed time: 61.52s]\n",
      "[Epoch 28/200] [D loss: 0.267649] [G loss: 1.535968] [Elapsed time: 63.60s]\n",
      "[Epoch 29/200] [D loss: 0.167730] [G loss: 2.271449] [Elapsed time: 65.73s]\n",
      "[Epoch 30/200] [D loss: 0.383059] [G loss: 4.043327] [Elapsed time: 67.79s]\n",
      "[Epoch 31/200] [D loss: 0.139971] [G loss: 2.301783] [Elapsed time: 69.99s]\n",
      "[Epoch 32/200] [D loss: 0.366368] [G loss: 4.583152] [Elapsed time: 72.16s]\n",
      "[Epoch 33/200] [D loss: 0.115930] [G loss: 2.051244] [Elapsed time: 74.40s]\n",
      "[Epoch 34/200] [D loss: 0.252021] [G loss: 1.261557] [Elapsed time: 76.70s]\n",
      "[Epoch 35/200] [D loss: 0.344853] [G loss: 0.954043] [Elapsed time: 78.89s]\n",
      "[Epoch 36/200] [D loss: 0.298277] [G loss: 2.734861] [Elapsed time: 80.94s]\n",
      "[Epoch 37/200] [D loss: 0.204032] [G loss: 1.851445] [Elapsed time: 83.25s]\n",
      "[Epoch 38/200] [D loss: 0.439454] [G loss: 4.073112] [Elapsed time: 85.53s]\n",
      "[Epoch 39/200] [D loss: 0.196844] [G loss: 2.271613] [Elapsed time: 87.83s]\n",
      "[Epoch 40/200] [D loss: 0.339134] [G loss: 1.112938] [Elapsed time: 90.07s]\n",
      "[Epoch 41/200] [D loss: 0.187284] [G loss: 2.158865] [Elapsed time: 92.15s]\n",
      "[Epoch 42/200] [D loss: 0.204809] [G loss: 3.333778] [Elapsed time: 94.24s]\n",
      "[Epoch 43/200] [D loss: 0.356498] [G loss: 4.664517] [Elapsed time: 96.37s]\n",
      "[Epoch 44/200] [D loss: 0.271913] [G loss: 1.495608] [Elapsed time: 98.59s]\n",
      "[Epoch 45/200] [D loss: 0.283297] [G loss: 1.851381] [Elapsed time: 100.76s]\n",
      "[Epoch 46/200] [D loss: 0.232715] [G loss: 1.843718] [Elapsed time: 102.94s]\n",
      "[Epoch 47/200] [D loss: 0.272580] [G loss: 2.443186] [Elapsed time: 105.15s]\n",
      "[Epoch 48/200] [D loss: 0.287602] [G loss: 1.447665] [Elapsed time: 107.25s]\n",
      "[Epoch 49/200] [D loss: 0.425887] [G loss: 1.284780] [Elapsed time: 109.35s]\n",
      "[Epoch 50/200] [D loss: 0.186046] [G loss: 2.177997] [Elapsed time: 111.61s]\n",
      "[Epoch 51/200] [D loss: 0.285513] [G loss: 1.232052] [Elapsed time: 113.77s]\n",
      "[Epoch 52/200] [D loss: 0.283873] [G loss: 2.362760] [Elapsed time: 115.90s]\n",
      "[Epoch 53/200] [D loss: 0.222242] [G loss: 2.055248] [Elapsed time: 118.17s]\n",
      "[Epoch 54/200] [D loss: 0.360279] [G loss: 1.282087] [Elapsed time: 120.40s]\n",
      "[Epoch 55/200] [D loss: 0.721383] [G loss: 5.014905] [Elapsed time: 122.58s]\n",
      "[Epoch 56/200] [D loss: 0.277877] [G loss: 1.767083] [Elapsed time: 124.75s]\n",
      "[Epoch 57/200] [D loss: 0.270824] [G loss: 2.197654] [Elapsed time: 127.02s]\n",
      "[Epoch 58/200] [D loss: 0.424543] [G loss: 3.150293] [Elapsed time: 129.18s]\n",
      "[Epoch 59/200] [D loss: 0.232277] [G loss: 2.365260] [Elapsed time: 131.34s]\n",
      "[Epoch 60/200] [D loss: 0.473773] [G loss: 3.130272] [Elapsed time: 133.57s]\n",
      "[Epoch 61/200] [D loss: 0.226312] [G loss: 2.579906] [Elapsed time: 135.66s]\n",
      "[Epoch 62/200] [D loss: 0.292613] [G loss: 2.699222] [Elapsed time: 137.81s]\n",
      "[Epoch 63/200] [D loss: 0.189525] [G loss: 2.307699] [Elapsed time: 140.07s]\n",
      "[Epoch 64/200] [D loss: 0.267687] [G loss: 1.922394] [Elapsed time: 142.13s]\n",
      "[Epoch 65/200] [D loss: 0.134780] [G loss: 2.453707] [Elapsed time: 144.30s]\n",
      "[Epoch 66/200] [D loss: 0.745672] [G loss: 5.832546] [Elapsed time: 146.50s]\n",
      "[Epoch 67/200] [D loss: 0.267983] [G loss: 1.247626] [Elapsed time: 148.74s]\n",
      "[Epoch 68/200] [D loss: 0.197923] [G loss: 1.855987] [Elapsed time: 150.89s]\n",
      "[Epoch 69/200] [D loss: 0.175693] [G loss: 2.044242] [Elapsed time: 153.02s]\n",
      "[Epoch 70/200] [D loss: 0.236401] [G loss: 1.698180] [Elapsed time: 155.25s]\n",
      "[Epoch 71/200] [D loss: 0.218862] [G loss: 2.137620] [Elapsed time: 157.43s]\n",
      "[Epoch 72/200] [D loss: 0.313574] [G loss: 2.971293] [Elapsed time: 159.57s]\n",
      "[Epoch 73/200] [D loss: 0.279411] [G loss: 1.445358] [Elapsed time: 161.79s]\n",
      "[Epoch 74/200] [D loss: 0.192544] [G loss: 2.558176] [Elapsed time: 163.98s]\n",
      "[Epoch 75/200] [D loss: 0.237893] [G loss: 2.864972] [Elapsed time: 166.14s]\n",
      "[Epoch 76/200] [D loss: 0.278976] [G loss: 1.421781] [Elapsed time: 168.36s]\n",
      "[Epoch 77/200] [D loss: 0.272979] [G loss: 1.546406] [Elapsed time: 170.49s]\n",
      "[Epoch 78/200] [D loss: 0.228164] [G loss: 1.973811] [Elapsed time: 172.67s]\n",
      "[Epoch 79/200] [D loss: 0.706613] [G loss: 5.111113] [Elapsed time: 174.88s]\n",
      "[Epoch 80/200] [D loss: 0.160206] [G loss: 2.751891] [Elapsed time: 177.13s]\n",
      "[Epoch 81/200] [D loss: 0.228012] [G loss: 1.372062] [Elapsed time: 179.36s]\n",
      "[Epoch 82/200] [D loss: 0.185978] [G loss: 3.285154] [Elapsed time: 181.48s]\n",
      "[Epoch 83/200] [D loss: 0.234544] [G loss: 2.080425] [Elapsed time: 183.61s]\n",
      "[Epoch 84/200] [D loss: 0.201549] [G loss: 3.033118] [Elapsed time: 185.70s]\n",
      "[Epoch 85/200] [D loss: 0.209546] [G loss: 1.726390] [Elapsed time: 187.89s]\n",
      "[Epoch 86/200] [D loss: 0.191814] [G loss: 1.584375] [Elapsed time: 190.04s]\n",
      "[Epoch 87/200] [D loss: 0.189289] [G loss: 1.956173] [Elapsed time: 192.13s]\n",
      "[Epoch 88/200] [D loss: 0.214115] [G loss: 2.445042] [Elapsed time: 194.21s]\n",
      "[Epoch 89/200] [D loss: 0.229225] [G loss: 1.887896] [Elapsed time: 196.33s]\n",
      "[Epoch 90/200] [D loss: 0.258727] [G loss: 1.918783] [Elapsed time: 198.48s]\n",
      "[Epoch 91/200] [D loss: 0.525155] [G loss: 4.670636] [Elapsed time: 200.63s]\n",
      "[Epoch 92/200] [D loss: 0.149629] [G loss: 2.665759] [Elapsed time: 202.93s]\n",
      "[Epoch 93/200] [D loss: 0.231752] [G loss: 1.992675] [Elapsed time: 205.15s]\n",
      "[Epoch 94/200] [D loss: 0.252092] [G loss: 1.369772] [Elapsed time: 207.19s]\n",
      "[Epoch 95/200] [D loss: 0.354619] [G loss: 3.468904] [Elapsed time: 209.46s]\n",
      "[Epoch 96/200] [D loss: 0.257331] [G loss: 1.730594] [Elapsed time: 211.52s]\n",
      "[Epoch 97/200] [D loss: 0.257057] [G loss: 1.626217] [Elapsed time: 213.63s]\n",
      "[Epoch 98/200] [D loss: 0.381525] [G loss: 2.710721] [Elapsed time: 215.76s]\n",
      "[Epoch 99/200] [D loss: 0.290752] [G loss: 1.729134] [Elapsed time: 217.95s]\n",
      "[Epoch 100/200] [D loss: 0.238628] [G loss: 2.645080] [Elapsed time: 220.11s]\n",
      "[Epoch 101/200] [D loss: 0.301505] [G loss: 2.494400] [Elapsed time: 222.22s]\n",
      "[Epoch 102/200] [D loss: 0.166729] [G loss: 1.940145] [Elapsed time: 224.57s]\n",
      "[Epoch 103/200] [D loss: 0.564058] [G loss: 4.985857] [Elapsed time: 226.73s]\n",
      "[Epoch 104/200] [D loss: 0.263062] [G loss: 1.714492] [Elapsed time: 229.00s]\n",
      "[Epoch 105/200] [D loss: 0.243098] [G loss: 1.906323] [Elapsed time: 231.20s]\n",
      "[Epoch 106/200] [D loss: 0.186166] [G loss: 1.919385] [Elapsed time: 233.31s]\n",
      "[Epoch 107/200] [D loss: 0.311186] [G loss: 3.207113] [Elapsed time: 235.52s]\n",
      "[Epoch 108/200] [D loss: 0.321304] [G loss: 1.266218] [Elapsed time: 237.69s]\n",
      "[Epoch 109/200] [D loss: 0.549747] [G loss: 0.714455] [Elapsed time: 239.95s]\n",
      "[Epoch 110/200] [D loss: 0.605282] [G loss: 4.304969] [Elapsed time: 242.07s]\n",
      "[Epoch 111/200] [D loss: 0.452816] [G loss: 0.972785] [Elapsed time: 244.18s]\n",
      "[Epoch 112/200] [D loss: 0.259560] [G loss: 2.553888] [Elapsed time: 246.37s]\n",
      "[Epoch 113/200] [D loss: 0.264185] [G loss: 2.004432] [Elapsed time: 248.59s]\n",
      "[Epoch 114/200] [D loss: 0.323853] [G loss: 1.773492] [Elapsed time: 250.84s]\n",
      "[Epoch 115/200] [D loss: 0.323026] [G loss: 3.561534] [Elapsed time: 253.04s]\n",
      "[Epoch 116/200] [D loss: 0.355829] [G loss: 2.340458] [Elapsed time: 255.23s]\n",
      "[Epoch 117/200] [D loss: 0.287203] [G loss: 1.875633] [Elapsed time: 257.38s]\n",
      "[Epoch 118/200] [D loss: 0.175472] [G loss: 2.835629] [Elapsed time: 259.62s]\n",
      "[Epoch 119/200] [D loss: 0.254357] [G loss: 1.692631] [Elapsed time: 261.84s]\n",
      "[Epoch 120/200] [D loss: 0.314360] [G loss: 1.704112] [Elapsed time: 264.02s]\n",
      "[Epoch 121/200] [D loss: 0.343226] [G loss: 2.748532] [Elapsed time: 266.19s]\n",
      "[Epoch 122/200] [D loss: 0.352772] [G loss: 1.471923] [Elapsed time: 268.31s]\n",
      "[Epoch 123/200] [D loss: 0.290773] [G loss: 1.825282] [Elapsed time: 270.38s]\n",
      "[Epoch 124/200] [D loss: 0.288054] [G loss: 2.338498] [Elapsed time: 272.67s]\n",
      "[Epoch 125/200] [D loss: 0.367791] [G loss: 1.453766] [Elapsed time: 274.94s]\n",
      "[Epoch 126/200] [D loss: 0.519084] [G loss: 0.774504] [Elapsed time: 277.26s]\n",
      "[Epoch 127/200] [D loss: 0.304498] [G loss: 2.074662] [Elapsed time: 279.46s]\n",
      "[Epoch 128/200] [D loss: 0.424916] [G loss: 2.136707] [Elapsed time: 281.70s]\n",
      "[Epoch 129/200] [D loss: 0.271950] [G loss: 2.024903] [Elapsed time: 283.87s]\n",
      "[Epoch 130/200] [D loss: 0.367038] [G loss: 1.214366] [Elapsed time: 286.03s]\n",
      "[Epoch 131/200] [D loss: 0.617455] [G loss: 0.593863] [Elapsed time: 288.19s]\n",
      "[Epoch 132/200] [D loss: 0.335486] [G loss: 2.621548] [Elapsed time: 290.41s]\n",
      "[Epoch 133/200] [D loss: 0.926742] [G loss: 4.369192] [Elapsed time: 292.61s]\n",
      "[Epoch 134/200] [D loss: 0.328658] [G loss: 1.737557] [Elapsed time: 294.90s]\n",
      "[Epoch 135/200] [D loss: 0.283550] [G loss: 1.961105] [Elapsed time: 297.11s]\n",
      "[Epoch 136/200] [D loss: 0.237803] [G loss: 1.631563] [Elapsed time: 299.37s]\n",
      "[Epoch 137/200] [D loss: 0.556557] [G loss: 0.666706] [Elapsed time: 301.53s]\n",
      "[Epoch 138/200] [D loss: 0.379531] [G loss: 1.484686] [Elapsed time: 303.66s]\n",
      "[Epoch 139/200] [D loss: 0.361954] [G loss: 1.517362] [Elapsed time: 305.88s]\n",
      "[Epoch 140/200] [D loss: 0.501792] [G loss: 2.812225] [Elapsed time: 308.03s]\n",
      "[Epoch 141/200] [D loss: 0.340909] [G loss: 1.993419] [Elapsed time: 310.23s]\n",
      "[Epoch 142/200] [D loss: 0.341758] [G loss: 1.533655] [Elapsed time: 312.50s]\n",
      "[Epoch 143/200] [D loss: 0.357699] [G loss: 1.879622] [Elapsed time: 314.69s]\n",
      "[Epoch 144/200] [D loss: 0.355635] [G loss: 1.337517] [Elapsed time: 316.86s]\n",
      "[Epoch 145/200] [D loss: 0.284494] [G loss: 1.949490] [Elapsed time: 318.99s]\n",
      "[Epoch 146/200] [D loss: 0.342236] [G loss: 1.291541] [Elapsed time: 321.11s]\n",
      "[Epoch 147/200] [D loss: 0.371238] [G loss: 1.163180] [Elapsed time: 323.28s]\n",
      "[Epoch 148/200] [D loss: 0.384957] [G loss: 1.648332] [Elapsed time: 325.40s]\n",
      "[Epoch 149/200] [D loss: 0.482092] [G loss: 2.585888] [Elapsed time: 327.54s]\n",
      "[Epoch 150/200] [D loss: 0.351355] [G loss: 1.810117] [Elapsed time: 329.80s]\n",
      "[Epoch 151/200] [D loss: 0.389585] [G loss: 2.867837] [Elapsed time: 331.92s]\n",
      "[Epoch 152/200] [D loss: 0.296492] [G loss: 2.042040] [Elapsed time: 334.07s]\n",
      "[Epoch 153/200] [D loss: 0.415388] [G loss: 1.514279] [Elapsed time: 336.27s]\n",
      "[Epoch 154/200] [D loss: 0.582690] [G loss: 3.243046] [Elapsed time: 338.43s]\n",
      "[Epoch 155/200] [D loss: 0.327851] [G loss: 1.240552] [Elapsed time: 340.73s]\n",
      "[Epoch 156/200] [D loss: 0.309236] [G loss: 2.684048] [Elapsed time: 342.78s]\n",
      "[Epoch 157/200] [D loss: 0.359937] [G loss: 1.768189] [Elapsed time: 345.04s]\n",
      "[Epoch 158/200] [D loss: 0.419313] [G loss: 2.949338] [Elapsed time: 347.18s]\n",
      "[Epoch 159/200] [D loss: 0.369428] [G loss: 1.686525] [Elapsed time: 349.47s]\n",
      "[Epoch 160/200] [D loss: 0.372725] [G loss: 1.910594] [Elapsed time: 351.75s]\n",
      "[Epoch 161/200] [D loss: 0.404691] [G loss: 2.192318] [Elapsed time: 353.95s]\n",
      "[Epoch 162/200] [D loss: 0.329726] [G loss: 1.278381] [Elapsed time: 356.12s]\n",
      "[Epoch 163/200] [D loss: 0.438956] [G loss: 1.107688] [Elapsed time: 358.27s]\n",
      "[Epoch 164/200] [D loss: 0.379808] [G loss: 1.296732] [Elapsed time: 360.52s]\n",
      "[Epoch 165/200] [D loss: 0.272419] [G loss: 1.871466] [Elapsed time: 362.68s]\n",
      "[Epoch 166/200] [D loss: 0.316327] [G loss: 2.217539] [Elapsed time: 364.84s]\n",
      "[Epoch 167/200] [D loss: 0.318068] [G loss: 2.809447] [Elapsed time: 366.93s]\n",
      "[Epoch 168/200] [D loss: 0.312213] [G loss: 2.378189] [Elapsed time: 369.18s]\n",
      "[Epoch 169/200] [D loss: 0.341580] [G loss: 1.740241] [Elapsed time: 371.39s]\n",
      "[Epoch 170/200] [D loss: 0.297123] [G loss: 1.438108] [Elapsed time: 373.71s]\n",
      "[Epoch 171/200] [D loss: 0.403347] [G loss: 2.504553] [Elapsed time: 375.88s]\n",
      "[Epoch 172/200] [D loss: 0.300613] [G loss: 2.286596] [Elapsed time: 378.06s]\n",
      "[Epoch 173/200] [D loss: 0.510907] [G loss: 1.088251] [Elapsed time: 380.25s]\n",
      "[Epoch 174/200] [D loss: 0.369480] [G loss: 2.691589] [Elapsed time: 382.43s]\n",
      "[Epoch 175/200] [D loss: 0.271048] [G loss: 2.371645] [Elapsed time: 384.46s]\n",
      "[Epoch 176/200] [D loss: 0.238992] [G loss: 2.155720] [Elapsed time: 386.78s]\n",
      "[Epoch 177/200] [D loss: 0.322650] [G loss: 1.660978] [Elapsed time: 388.99s]\n",
      "[Epoch 178/200] [D loss: 0.241093] [G loss: 1.964277] [Elapsed time: 391.24s]\n",
      "[Epoch 179/200] [D loss: 0.431742] [G loss: 3.381077] [Elapsed time: 393.49s]\n",
      "[Epoch 180/200] [D loss: 0.354453] [G loss: 1.221591] [Elapsed time: 395.68s]\n",
      "[Epoch 181/200] [D loss: 0.258100] [G loss: 2.365489] [Elapsed time: 397.82s]\n",
      "[Epoch 182/200] [D loss: 0.233358] [G loss: 1.919914] [Elapsed time: 399.96s]\n",
      "[Epoch 183/200] [D loss: 0.711361] [G loss: 4.079828] [Elapsed time: 402.08s]\n",
      "[Epoch 184/200] [D loss: 0.316330] [G loss: 2.098958] [Elapsed time: 404.28s]\n",
      "[Epoch 185/200] [D loss: 0.229378] [G loss: 2.687684] [Elapsed time: 406.44s]\n",
      "[Epoch 186/200] [D loss: 0.373509] [G loss: 3.000597] [Elapsed time: 408.63s]\n",
      "[Epoch 187/200] [D loss: 0.326225] [G loss: 1.284205] [Elapsed time: 410.94s]\n",
      "[Epoch 188/200] [D loss: 0.288506] [G loss: 1.971441] [Elapsed time: 413.07s]\n",
      "[Epoch 189/200] [D loss: 0.287005] [G loss: 3.074135] [Elapsed time: 415.30s]\n",
      "[Epoch 190/200] [D loss: 0.390802] [G loss: 2.588845] [Elapsed time: 417.60s]\n",
      "[Epoch 191/200] [D loss: 0.355655] [G loss: 1.389329] [Elapsed time: 419.73s]\n",
      "[Epoch 192/200] [D loss: 0.271143] [G loss: 1.435653] [Elapsed time: 421.90s]\n",
      "[Epoch 193/200] [D loss: 0.270114] [G loss: 1.769731] [Elapsed time: 424.00s]\n",
      "[Epoch 194/200] [D loss: 0.324468] [G loss: 1.234152] [Elapsed time: 426.18s]\n",
      "[Epoch 195/200] [D loss: 0.339478] [G loss: 2.468923] [Elapsed time: 428.44s]\n",
      "[Epoch 196/200] [D loss: 0.282833] [G loss: 1.452113] [Elapsed time: 430.45s]\n",
      "[Epoch 197/200] [D loss: 0.351173] [G loss: 1.290493] [Elapsed time: 432.70s]\n",
      "[Epoch 198/200] [D loss: 0.238157] [G loss: 2.610739] [Elapsed time: 434.87s]\n",
      "[Epoch 199/200] [D loss: 0.332583] [G loss: 1.189172] [Elapsed time: 436.96s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# number of epochs of training\n",
    "n_epochs = 200\n",
    "\n",
    "# interval between image samples\n",
    "sample_interval = 2000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        ## 실제 이미지는 1로, 가짜 이미지는 0으로 label됩니다.\n",
    "        real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        ## random sampling한 값인 z를 생성자에 넣어 이미지를 생성합니다.\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        ## 생성된 이미지를 discriminator가 판별하게 한 후, loss값을 계산합니다.\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        ## 실제 이미지는 real(1)로, 가짜 이미지는 fake(0)으로 판별하도록 계산합니다.\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"dataset/data{epoch}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1 - GAN",
   "provenance": [
    {
     "file_id": "https://github.com/happy-jihye/GAN/blob/main/gan/gan.ipynb",
     "timestamp": 1736222486376
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
